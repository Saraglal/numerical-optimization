## Adaptive Optimizers

This lab focuses on adaptive optimization algorithms, including Adagrad, RMSProp, and Adam. The `adaptive_optimizers.py` script contains implementations of these adaptive optimization techniques.
